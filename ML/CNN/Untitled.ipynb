{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST画像　グレースケール　0~1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "<class 'numpy.float32'>\n",
      "[[[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.01176471]\n",
      "  [0.07058824]\n",
      "  [0.07058824]\n",
      "  [0.07058824]\n",
      "  [0.49411765]\n",
      "  [0.53333336]\n",
      "  [0.6862745 ]\n",
      "  [0.10196079]\n",
      "  [0.6509804 ]\n",
      "  [1.        ]\n",
      "  [0.96862745]\n",
      "  [0.49803922]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.11764706]\n",
      "  [0.14117648]\n",
      "  [0.36862746]\n",
      "  [0.6039216 ]\n",
      "  [0.6666667 ]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.88235295]\n",
      "  [0.6745098 ]\n",
      "  [0.99215686]\n",
      "  [0.9490196 ]\n",
      "  [0.7647059 ]\n",
      "  [0.2509804 ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.19215687]\n",
      "  [0.93333334]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.9843137 ]\n",
      "  [0.3647059 ]\n",
      "  [0.32156864]\n",
      "  [0.32156864]\n",
      "  [0.21960784]\n",
      "  [0.15294118]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.07058824]\n",
      "  [0.85882354]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.7764706 ]\n",
      "  [0.7137255 ]\n",
      "  [0.96862745]\n",
      "  [0.94509804]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.3137255 ]\n",
      "  [0.6117647 ]\n",
      "  [0.41960785]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.8039216 ]\n",
      "  [0.04313726]\n",
      "  [0.        ]\n",
      "  [0.16862746]\n",
      "  [0.6039216 ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.05490196]\n",
      "  [0.00392157]\n",
      "  [0.6039216 ]\n",
      "  [0.99215686]\n",
      "  [0.3529412 ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.54509807]\n",
      "  [0.99215686]\n",
      "  [0.74509805]\n",
      "  [0.00784314]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.04313726]\n",
      "  [0.74509805]\n",
      "  [0.99215686]\n",
      "  [0.27450982]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.13725491]\n",
      "  [0.94509804]\n",
      "  [0.88235295]\n",
      "  [0.627451  ]\n",
      "  [0.42352942]\n",
      "  [0.00392157]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.31764707]\n",
      "  [0.9411765 ]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.46666667]\n",
      "  [0.09803922]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.1764706 ]\n",
      "  [0.7294118 ]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.5882353 ]\n",
      "  [0.10588235]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.0627451 ]\n",
      "  [0.3647059 ]\n",
      "  [0.9882353 ]\n",
      "  [0.99215686]\n",
      "  [0.73333335]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.9764706 ]\n",
      "  [0.99215686]\n",
      "  [0.9764706 ]\n",
      "  [0.2509804 ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.18039216]\n",
      "  [0.50980395]\n",
      "  [0.7176471 ]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.8117647 ]\n",
      "  [0.00784314]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.15294118]\n",
      "  [0.5803922 ]\n",
      "  [0.8980392 ]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.98039216]\n",
      "  [0.7137255 ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.09411765]\n",
      "  [0.44705883]\n",
      "  [0.8666667 ]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.7882353 ]\n",
      "  [0.30588236]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.09019608]\n",
      "  [0.25882354]\n",
      "  [0.8352941 ]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.7764706 ]\n",
      "  [0.31764707]\n",
      "  [0.00784314]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.07058824]\n",
      "  [0.67058825]\n",
      "  [0.85882354]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.7647059 ]\n",
      "  [0.3137255 ]\n",
      "  [0.03529412]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.21568628]\n",
      "  [0.6745098 ]\n",
      "  [0.8862745 ]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.95686275]\n",
      "  [0.52156866]\n",
      "  [0.04313726]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.53333336]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.83137256]\n",
      "  [0.5294118 ]\n",
      "  [0.5176471 ]\n",
      "  [0.0627451 ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#データの読み込みと前処理\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "#kerasでCNN構築\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.optimizers import Adam\n",
    "#時間計測\n",
    "import time\n",
    " \n",
    " \n",
    "'''\n",
    "データの読み込みと前処理\n",
    "'''\n",
    "#データの読み込み\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    " \n",
    "#訓練データ\n",
    "X_train = X_train.reshape(60000, 28, 28, 1)\n",
    "X_train = X_train.astype('float32')#型を変更\n",
    "X_train /= 255 #0から1.0の範囲に変換\n",
    "print(X_train.max())\n",
    "print(type(X_train[0][0][0][0]))\n",
    "#正解ラベル\n",
    "correct = 10\n",
    "y_train = np_utils.to_categorical(y_train, correct)\n",
    " \n",
    "#テストデータ\n",
    "X_test = X_test.reshape(10000, 28, 28, 1)\n",
    "X_test = X_test.astype('float32')\n",
    "X_test /= 255\n",
    " \n",
    "y_test = np_utils.to_categorical(y_test, correct)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 15s 245us/step - loss: 0.2335 - acc: 0.9335 - val_loss: 0.1010 - val_acc: 0.9725.2460 - ETA: 0s - loss: 0.2363 - acc: 0\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 15s 252us/step - loss: 0.0813 - acc: 0.9764 - val_loss: 0.0674 - val_acc: 0.9782\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 17s 277us/step - loss: 0.0581 - acc: 0.9830 - val_loss: 0.0633 - val_acc: 0.9801\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 15s 244us/step - loss: 0.0458 - acc: 0.9864 - val_loss: 0.0579 - val_acc: 0.9814\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 15s 246us/step - loss: 0.0370 - acc: 0.9890 - val_loss: 0.0631 - val_acc: 0.9807\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 15s 246us/step - loss: 0.0304 - acc: 0.9910 - val_loss: 0.0602 - val_acc: 0.981700 - acc:  - ETA: 1s - \n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 14s 240us/step - loss: 0.0241 - acc: 0.9927 - val_loss: 0.0637 - val_acc: 0.9809\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 15s 242us/step - loss: 0.0206 - acc: 0.9940 - val_loss: 0.0599 - val_acc: 0.9826\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 18s 294us/step - loss: 0.0161 - acc: 0.9955 - val_loss: 0.0670 - val_acc: 0.9815\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 29s 486us/step - loss: 0.0132 - acc: 0.9964 - val_loss: 0.0723 - val_acc: 0.9802\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 15s 254us/step - loss: 0.0113 - acc: 0.9969 - val_loss: 0.0657 - val_acc: 0.9823\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 14s 241us/step - loss: 0.0096 - acc: 0.9975 - val_loss: 0.0701 - val_acc: 0.9824\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 15s 251us/step - loss: 0.0077 - acc: 0.9980 - val_loss: 0.0684 - val_acc: 0.9827\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 16s 268us/step - loss: 0.0060 - acc: 0.9986 - val_loss: 0.0729 - val_acc: 0.9819\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 16s 259us/step - loss: 0.0052 - acc: 0.9988 - val_loss: 0.0820 - val_acc: 0.9801\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 15s 244us/step - loss: 0.0052 - acc: 0.9986 - val_loss: 0.0843 - val_acc: 0.9796\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 15s 244us/step - loss: 0.0047 - acc: 0.9987 - val_loss: 0.0826 - val_acc: 0.98150s - loss: 0.0045 - acc:  - ETA: 0s - loss: 0.0046 - ac\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 14s 240us/step - loss: 0.0045 - acc: 0.9987 - val_loss: 0.0809 - val_acc: 0.9822 - ETA: 6s - loss: 0\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 15s 242us/step - loss: 0.0024 - acc: 0.9996 - val_loss: 0.0817 - val_acc: 0.9819\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 15s 253us/step - loss: 0.0016 - acc: 0.9998 - val_loss: 0.0855 - val_acc: 0.9811\n",
      "Test Loss:0.085\n",
      "Test accuracy:0.981\n",
      "time:317.341sec\n"
     ]
    }
   ],
   "source": [
    " \n",
    "'''\n",
    "CNNの構築\n",
    "'''\n",
    " \n",
    "model = Sequential()\n",
    " \n",
    "model.add(Conv2D(filters=32, kernel_size=(3,3), padding='same', input_shape=(28, 28, 1), activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add\n",
    "model.add(Dense(10, activation='softmax'))\n",
    " \n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    " \n",
    "'''\n",
    "学習\n",
    "'''\n",
    "#計測開始\n",
    "startTime = time.time()\n",
    " \n",
    "history = model.fit(X_train, y_train, epochs=1, batch_size=100, verbose=1, validation_data=(X_test, y_test))\n",
    " \n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "timer = time.time() - startTime\n",
    "print('Test Loss:{0:.3f}'.format(score[0]))\n",
    "print('Test accuracy:{0:.3}'.format(score[1]))\n",
    "#処理時間\n",
    "print(\"time:{0:.3f}sec\".format(timer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sample.txt', 'w') as f:\n",
    "  # 書き込み\n",
    "  f.writelines('Test Loss:{0:.3f}'.format(score[0])+\"\\n\")\n",
    "  f.writelines('Test accuracy:{0:.3}'.format(score[1])+\"\\n\")\n",
    "  f.writelines(\"time:{0:.3f}sec\".format(timer)+)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST画像　グレースケール　0~255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  3.]\n",
      "  [ 18.]\n",
      "  [ 18.]\n",
      "  [ 18.]\n",
      "  [126.]\n",
      "  [136.]\n",
      "  [175.]\n",
      "  [ 26.]\n",
      "  [166.]\n",
      "  [255.]\n",
      "  [247.]\n",
      "  [127.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [ 30.]\n",
      "  [ 36.]\n",
      "  [ 94.]\n",
      "  [154.]\n",
      "  [170.]\n",
      "  [253.]\n",
      "  [253.]\n",
      "  [253.]\n",
      "  [253.]\n",
      "  [253.]\n",
      "  [225.]\n",
      "  [172.]\n",
      "  [253.]\n",
      "  [242.]\n",
      "  [195.]\n",
      "  [ 64.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [ 49.]\n",
      "  [238.]\n",
      "  [253.]\n",
      "  [253.]\n",
      "  [253.]\n",
      "  [253.]\n",
      "  [253.]\n",
      "  [253.]\n",
      "  [253.]\n",
      "  [253.]\n",
      "  [251.]\n",
      "  [ 93.]\n",
      "  [ 82.]\n",
      "  [ 82.]\n",
      "  [ 56.]\n",
      "  [ 39.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [ 18.]\n",
      "  [219.]\n",
      "  [253.]\n",
      "  [253.]\n",
      "  [253.]\n",
      "  [253.]\n",
      "  [253.]\n",
      "  [198.]\n",
      "  [182.]\n",
      "  [247.]\n",
      "  [241.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [ 80.]\n",
      "  [156.]\n",
      "  [107.]\n",
      "  [253.]\n",
      "  [253.]\n",
      "  [205.]\n",
      "  [ 11.]\n",
      "  [  0.]\n",
      "  [ 43.]\n",
      "  [154.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [ 14.]\n",
      "  [  1.]\n",
      "  [154.]\n",
      "  [253.]\n",
      "  [ 90.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [139.]\n",
      "  [253.]\n",
      "  [190.]\n",
      "  [  2.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [ 11.]\n",
      "  [190.]\n",
      "  [253.]\n",
      "  [ 70.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [ 35.]\n",
      "  [241.]\n",
      "  [225.]\n",
      "  [160.]\n",
      "  [108.]\n",
      "  [  1.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [ 81.]\n",
      "  [240.]\n",
      "  [253.]\n",
      "  [253.]\n",
      "  [119.]\n",
      "  [ 25.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [ 45.]\n",
      "  [186.]\n",
      "  [253.]\n",
      "  [253.]\n",
      "  [150.]\n",
      "  [ 27.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [ 16.]\n",
      "  [ 93.]\n",
      "  [252.]\n",
      "  [253.]\n",
      "  [187.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [249.]\n",
      "  [253.]\n",
      "  [249.]\n",
      "  [ 64.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [ 46.]\n",
      "  [130.]\n",
      "  [183.]\n",
      "  [253.]\n",
      "  [253.]\n",
      "  [207.]\n",
      "  [  2.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [ 39.]\n",
      "  [148.]\n",
      "  [229.]\n",
      "  [253.]\n",
      "  [253.]\n",
      "  [253.]\n",
      "  [250.]\n",
      "  [182.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [ 24.]\n",
      "  [114.]\n",
      "  [221.]\n",
      "  [253.]\n",
      "  [253.]\n",
      "  [253.]\n",
      "  [253.]\n",
      "  [201.]\n",
      "  [ 78.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [ 23.]\n",
      "  [ 66.]\n",
      "  [213.]\n",
      "  [253.]\n",
      "  [253.]\n",
      "  [253.]\n",
      "  [253.]\n",
      "  [198.]\n",
      "  [ 81.]\n",
      "  [  2.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [ 18.]\n",
      "  [171.]\n",
      "  [219.]\n",
      "  [253.]\n",
      "  [253.]\n",
      "  [253.]\n",
      "  [253.]\n",
      "  [195.]\n",
      "  [ 80.]\n",
      "  [  9.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [ 55.]\n",
      "  [172.]\n",
      "  [226.]\n",
      "  [253.]\n",
      "  [253.]\n",
      "  [253.]\n",
      "  [253.]\n",
      "  [244.]\n",
      "  [133.]\n",
      "  [ 11.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [136.]\n",
      "  [253.]\n",
      "  [253.]\n",
      "  [253.]\n",
      "  [212.]\n",
      "  [135.]\n",
      "  [132.]\n",
      "  [ 16.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]]\n"
     ]
    }
   ],
   "source": [
    " \n",
    "'''\n",
    "データの読み込みと前処理\n",
    "'''\n",
    "#データの読み込み\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "#訓練データ\n",
    "X_train = X_train.reshape(60000, 28, 28, 1)\n",
    "X_train = X_train.astype('float32')#型を変更\n",
    "#X_train /= 255 #0から1.0の範囲に変換\n",
    " \n",
    "#正解ラベル\n",
    "correct = 10\n",
    "y_train = np_utils.to_categorical(y_train, correct)\n",
    " \n",
    "#テストデータ\n",
    "X_test = X_test.reshape(10000, 28, 28, 1)\n",
    "X_test = X_test.astype('float32')\n",
    "#X_test /= 255\n",
    " \n",
    "y_test = np_utils.to_categorical(y_test, correct)\n",
    "\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 19s 316us/step - loss: 8.6593 - acc: 0.4610 - val_loss: 8.5520 - val_acc: 0.4685\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 18s 308us/step - loss: 8.3443 - acc: 0.4816 - val_loss: 8.3932 - val_acc: 0.4786\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 18s 307us/step - loss: 8.2844 - acc: 0.4854 - val_loss: 8.3537 - val_acc: 0.4813\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 16s 275us/step - loss: 8.2574 - acc: 0.4873 - val_loss: 8.3666 - val_acc: 0.4802\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 15s 257us/step - loss: 8.0335 - acc: 0.5009 - val_loss: 7.5656 - val_acc: 0.5299\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 16s 259us/step - loss: 7.0071 - acc: 0.5642 - val_loss: 7.0629 - val_acc: 0.5612\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 17s 289us/step - loss: 6.8701 - acc: 0.5731 - val_loss: 6.9565 - val_acc: 0.5676\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 19s 320us/step - loss: 6.0964 - acc: 0.6208 - val_loss: 3.9389 - val_acc: 0.7538\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 19s 316us/step - loss: 3.7647 - acc: 0.7650 - val_loss: 3.7110 - val_acc: 0.7689\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 19s 323us/step - loss: 3.6636 - acc: 0.7715 - val_loss: 3.7063 - val_acc: 0.7691\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 19s 317us/step - loss: 3.5844 - acc: 0.7767 - val_loss: 3.6030 - val_acc: 0.7755\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 19s 313us/step - loss: 3.5304 - acc: 0.7801 - val_loss: 3.5823 - val_acc: 0.7768\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 19s 308us/step - loss: 3.5129 - acc: 0.7812 - val_loss: 3.6069 - val_acc: 0.7753\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 17s 282us/step - loss: 3.4942 - acc: 0.7823 - val_loss: 3.5612 - val_acc: 0.7782\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 19s 312us/step - loss: 3.4791 - acc: 0.7835 - val_loss: 3.5605 - val_acc: 0.7789\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 19s 314us/step - loss: 3.4682 - acc: 0.7841 - val_loss: 3.6554 - val_acc: 0.7724\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 19s 314us/step - loss: 3.4719 - acc: 0.7839 - val_loss: 3.5852 - val_acc: 0.7764\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 19s 313us/step - loss: 3.4706 - acc: 0.7842 - val_loss: 3.5453 - val_acc: 0.7793\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 19s 320us/step - loss: 3.4603 - acc: 0.7847 - val_loss: 3.5636 - val_acc: 0.7784\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 17s 282us/step - loss: 3.4521 - acc: 0.7852 - val_loss: 3.5600 - val_acc: 0.7782\n",
      "Test Loss:3.560\n",
      "Test accuracy:0.778\n",
      "time:363.810sec\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "CNNの構築\n",
    "'''\n",
    " \n",
    "model = Sequential()\n",
    " \n",
    "model.add(Conv2D(filters=32, kernel_size=(3,3), padding='same', input_shape=(28, 28, 1), activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add\n",
    "model.add(Dense(10, activation='softmax'))\n",
    " \n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    " \n",
    "'''\n",
    "学習\n",
    "'''\n",
    "#計測開始\n",
    "startTime = time.time()\n",
    " \n",
    "history = model.fit(X_train, y_train, epochs=20, batch_size=100, verbose=1, validation_data=(X_test, y_test))\n",
    " \n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    " \n",
    "print('Test Loss:{0:.3f}'.format(score[0]))\n",
    "print('Test accuracy:{0:.3}'.format(score[1]))\n",
    "#処理時間\n",
    "print(\"time:{0:.3f}sec\".format(time.time() - startTime))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST画像　グレースケール　２値化　0 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "データの読み込みと前処理\n",
    "'''\n",
    "#データの読み込み\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "#訓練データ\n",
    "#2値化\n",
    "ret, X_train = cv2.threshold(X_train, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "X_train = X_train.reshape(60000, 28, 28, 1)\n",
    "\n",
    "X_train = X_train.astype('float32')#型を変更\n",
    "X_train /= 255 #0から1.0の範囲に変換\n",
    "\n",
    "#正解ラベル\n",
    "correct = 10\n",
    "y_train = np_utils.to_categorical(y_train, correct)\n",
    " \n",
    "#テストデータ\n",
    "#2値化\n",
    "ret, X_test = cv2.threshold(X_test, 127, 255, cv2.THRESH_BINARY)\n",
    "X_test = X_test.reshape(10000, 28, 28, 1)\n",
    "X_test = X_test.astype('float32')\n",
    "X_test /= 255\n",
    " \n",
    "y_test = np_utils.to_categorical(y_test, correct)\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 19s 309us/step - loss: 0.2606 - acc: 0.9263 - val_loss: 0.1073 - val_acc: 0.9686\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 18s 305us/step - loss: 0.0853 - acc: 0.9755 - val_loss: 0.0829 - val_acc: 0.9747\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 19s 310us/step - loss: 0.0573 - acc: 0.9834 - val_loss: 0.0707 - val_acc: 0.9775\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 17s 286us/step - loss: 0.0424 - acc: 0.9873 - val_loss: 0.0684 - val_acc: 0.9778\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 16s 261us/step - loss: 0.0326 - acc: 0.9901 - val_loss: 0.0712 - val_acc: 0.9782\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 17s 278us/step - loss: 0.0253 - acc: 0.9927 - val_loss: 0.0756 - val_acc: 0.9786\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 19s 311us/step - loss: 0.0191 - acc: 0.9948 - val_loss: 0.0800 - val_acc: 0.9776\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 18s 305us/step - loss: 0.0155 - acc: 0.9958 - val_loss: 0.0798 - val_acc: 0.9780\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 18s 301us/step - loss: 0.0121 - acc: 0.9968 - val_loss: 0.0799 - val_acc: 0.9783\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 18s 301us/step - loss: 0.0101 - acc: 0.9975 - val_loss: 0.0859 - val_acc: 0.9767\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 18s 295us/step - loss: 0.0078 - acc: 0.9983 - val_loss: 0.1005 - val_acc: 0.9769\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 20s 335us/step - loss: 0.0070 - acc: 0.9981 - val_loss: 0.0938 - val_acc: 0.9776\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 19s 316us/step - loss: 0.0055 - acc: 0.9987 - val_loss: 0.0977 - val_acc: 0.9767\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 19s 311us/step - loss: 0.0043 - acc: 0.9991 - val_loss: 0.1033 - val_acc: 0.9755\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 19s 311us/step - loss: 0.0043 - acc: 0.9990 - val_loss: 0.1055 - val_acc: 0.9773\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 19s 317us/step - loss: 0.0031 - acc: 0.9994 - val_loss: 0.1103 - val_acc: 0.9778\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 18s 306us/step - loss: 0.0064 - acc: 0.9981 - val_loss: 0.1160 - val_acc: 0.9758\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 16s 271us/step - loss: 0.0041 - acc: 0.9989 - val_loss: 0.1079 - val_acc: 0.9783\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 18s 302us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.1141 - val_acc: 0.9772\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 19s 313us/step - loss: 5.2498e-04 - acc: 1.0000 - val_loss: 0.1142 - val_acc: 0.9781\n",
      "Test Loss:0.114\n",
      "Test accuracy:0.978\n",
      "time:363.753sec\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "CNNの構築\n",
    "'''\n",
    " \n",
    "model = Sequential()\n",
    " \n",
    "model.add(Conv2D(filters=32, kernel_size=(3,3), padding='same', input_shape=(28, 28, 1), activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add\n",
    "model.add(Dense(10, activation='softmax'))\n",
    " \n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    " \n",
    "'''\n",
    "学習\n",
    "'''\n",
    "#計測開始\n",
    "startTime = time.time()\n",
    " \n",
    "history = model.fit(X_train, y_train, epochs=20, batch_size=100, verbose=1, validation_data=(X_test, y_test))\n",
    " \n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    " \n",
    "timer = time.time() - startTime\n",
    "\n",
    "#損失\n",
    "print('Test Loss:{0:.3f}'.format(score[0]))\n",
    "\n",
    "#精度\n",
    "print('Test accuracy:{0:.3}'.format(score[1]))\n",
    "\n",
    "# 処理時間\n",
    "print(\"time:{0:.3f}sec\".format(timer))\n",
    "\n",
    "#ファイル出力\n",
    "with open('MNIST_gray_conv_dense.txt', 'w') as f:\n",
    "  # 書き込み\n",
    "  f.writelines('Test Loss:{0:.3f}'.format(score[0])+\"\\n\")\n",
    "  f.writelines('Test accuracy:{0:.3}'.format(score[1])+\"\\n\")\n",
    "  f.writelines(\"time:{0:.3f}sec\".format(timer)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: RuntimeWarning: divide by zero encountered in log\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8849646\n",
      "(60000, 28, 28, 1)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "#データの読み込み\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "#訓練データ\n",
    "#フーリエ変換\n",
    "X_train = np.fft.fft2(X_train)\n",
    "X_train = np.fft.fftshift(X_train)\n",
    "X_train = 20*np.log(np.abs(X_train))\n",
    "\n",
    "X_train = X_train.reshape(60000, 28, 28, 1)\n",
    "X_train = X_train.astype('float32')#型を変更\n",
    "X_train /= 255 #0から1.0の範囲に変換\n",
    "print(X_train.max())\n",
    "print(X_train.shape)\n",
    "print(type(X_train[0][0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function ndarray.max>"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#データの読み込み\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "#訓練データ\n",
    "#フーリエ変換\n",
    "X_train = np.fft.fft2(X_train)\n",
    "X_train = np.fft.fftshift(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(X_train).min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# グレースケール　フーリエ変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "データの読み込みと前処理\n",
    "'''\n",
    "#データの読み込み\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "#フーリエ変換\n",
    "X_train = np.fft.fft2(X_train)\n",
    "X_train = np.fft.fftshift(X_train)\n",
    "X_train = np.abs(X_train)\n",
    "X_train = X_train.reshape(60000, 28, 28, 1)\n",
    "X_train = X_train.astype('float32')#型を変更\n",
    "X_train /= X_train.max() #0から1.0の範囲に変換\n",
    "\n",
    "#正解ラベル\n",
    "correct = 10\n",
    "y_train = np_utils.to_categorical(y_train, correct)\n",
    " \n",
    "#テストデータ\n",
    "#フーリエ変換\n",
    "X_test = np.fft.fft2(X_test)\n",
    "X_test = np.fft.fftshift(X_test)\n",
    "X_test = np.abs(X_test)\n",
    "X_test = X_test.reshape(10000, 28, 28, 1)\n",
    "X_test = X_test.astype('float32')\n",
    "X_test /= X_test.max()\n",
    " \n",
    "y_test = np_utils.to_categorical(y_test, correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 19s 314us/step - loss: 2.3018 - acc: 0.1116 - val_loss: 2.3012 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 19s 315us/step - loss: 2.3013 - acc: 0.1118 - val_loss: 2.3011 - val_acc: 0.1134\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 18s 307us/step - loss: 2.3009 - acc: 0.1126 - val_loss: 2.3020 - val_acc: 0.1129\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 19s 312us/step - loss: 2.3004 - acc: 0.1125 - val_loss: 2.3028 - val_acc: 0.1026\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 19s 311us/step - loss: 2.2997 - acc: 0.1142 - val_loss: 2.3042 - val_acc: 0.1032\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 17s 286us/step - loss: 2.2990 - acc: 0.1165 - val_loss: 2.3044 - val_acc: 0.1033\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 17s 284us/step - loss: 2.2976 - acc: 0.1174 - val_loss: 2.3061 - val_acc: 0.1039\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 18s 307us/step - loss: 2.2961 - acc: 0.1199 - val_loss: 2.3069 - val_acc: 0.1031\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 163s 3ms/step - loss: 2.2942 - acc: 0.1212 - val_loss: 2.3085 - val_acc: 0.1030\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 17s 292us/step - loss: 2.2918 - acc: 0.1261 - val_loss: 2.3134 - val_acc: 0.1001\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 16s 271us/step - loss: 2.2888 - acc: 0.1288 - val_loss: 2.3209 - val_acc: 0.1024\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 16s 268us/step - loss: 2.2850 - acc: 0.1325 - val_loss: 2.3221 - val_acc: 0.0945\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 17s 284us/step - loss: 2.2815 - acc: 0.1359 - val_loss: 2.3190 - val_acc: 0.1026\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 19s 315us/step - loss: 2.2775 - acc: 0.1405 - val_loss: 2.3215 - val_acc: 0.1018\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 20s 326us/step - loss: 2.2729 - acc: 0.1452 - val_loss: 2.3263 - val_acc: 0.0990\n",
      "Epoch 16/20\n",
      " 4400/60000 [=>............................] - ETA: 21s - loss: 2.2658 - acc: 0.1539"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-192-136ba5211e59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mstartTime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1000\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1002\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "CNNの構築\n",
    "'''\n",
    " \n",
    "model = Sequential()\n",
    " \n",
    "model.add(Conv2D(filters=32, kernel_size=(3,3), padding='same', input_shape=(28, 28, 1), activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add\n",
    "model.add(Dense(10, activation='softmax'))\n",
    " \n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    " \n",
    "'''\n",
    "学習\n",
    "'''\n",
    "#計測開始\n",
    "startTime = time.time()\n",
    " \n",
    "history = model.fit(X_train, y_train, epochs=20, batch_size=100, verbose=1, validation_data=(X_test, y_test))\n",
    " \n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    " \n",
    "print('Test Loss:{0:.3f}'.format(score[0]))\n",
    "print('Test accuracy:{0:.3}'.format(score[1]))\n",
    "#処理時間\n",
    "print(\"time:{0:.3f}sec\".format(time.time() - startTime))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# グレースケール　フーリエ変換　グレースケール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "/opt/concourse/worker/volumes/live/d8bcd4d1-79b2-4aa5-797a-b95097f1118f/volume/opencv_1512680501887/work/modules/imgproc/src/color.cpp:11010: error: (-215) depth == 0 || depth == 2 || depth == 5 in function cvtColor\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-193-24db136eff99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfftshift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_RGB2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m60000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#型を変更\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: /opt/concourse/worker/volumes/live/d8bcd4d1-79b2-4aa5-797a-b95097f1118f/volume/opencv_1512680501887/work/modules/imgproc/src/color.cpp:11010: error: (-215) depth == 0 || depth == 2 || depth == 5 in function cvtColor\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "データの読み込みと前処理\n",
    "'''\n",
    "#データの読み込み\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "#フーリエ変換\n",
    "X_train = np.fft.fft2(X_train)\n",
    "X_train = np.fft.fftshift(X_train)\n",
    "X_train = np.abs(X_train)\n",
    "X_train = cv2.cvtColor(X_train, cv2.COLOR_RGB2GRAY)\n",
    "X_train = X_train.reshape(60000, 28, 28, 1)\n",
    "X_train = X_train.astype('float32')#型を変更\n",
    "X_train /= X_train.max() #0から1.0の範囲に変換\n",
    "\n",
    "#正解ラベル\n",
    "correct = 10\n",
    "y_train = np_utils.to_categorical(y_train, correct)\n",
    " \n",
    "#テストデータ\n",
    "#フーリエ変換\n",
    "X_test = np.fft.fft2(X_test)\n",
    "X_test = np.fft.fftshift(X_test)\n",
    "X_test = np.abs(X_test)\n",
    "X_test = cv2.cvtColor(X_test, cv2.COLOR_RGB2GRAY)\n",
    "X_test = X_test.reshape(10000, 28, 28, 1)\n",
    "X_test = X_test.astype('float32')\n",
    "X_test /= X_test.max()\n",
    " \n",
    "y_test = np_utils.to_categorical(y_test, correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "loss = []\n",
    "while(i < 5):\n",
    "    print(i)\n",
    "    loss.append(i)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sample.txt', 'w') as f:\n",
    "    for x in loss:\n",
    "        f.write(str(x) + \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "loss = pd.DataFrame(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "loss = pd.DataFrame(loss)\n",
    "loss.to_csv(\"sample.csv\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    " \n",
    "model.add(Conv2D(filters=32, kernel_size=(3,3), padding='same', input_shape=(28, 28, 1), activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add\n",
    "model.add(Dense(10, activation='softmax'))\n",
    " \n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                250890    \n",
      "=================================================================\n",
      "Total params: 251,210\n",
      "Trainable params: 251,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=10\n",
    "with open('MNIST_ZeroDL_summary.txt', 'w') as f:\n",
    "  # 書き込み\n",
    "  f.writelines(str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                250890    \n",
      "=================================================================\n",
      "Total params: 251,210\n",
      "Trainable params: 251,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "keras.utils.print_summary(model, line_length=None, positions=None, print_fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# データの読み込みと前処理\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "# kerasでCNN構築\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.optimizers import Adam\n",
    "# 時間計測\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "\n",
    "'''\n",
    "データの読み込みと前処理\n",
    "'''\n",
    "# データの読み込み\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# 訓練データ\n",
    "# 2値化\n",
    "ret, X_train = cv2.threshold(X_train, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "X_train = X_train.reshape(60000, 28, 28, 1)\n",
    "\n",
    "X_train = X_train.astype('float32')  # 型を変更\n",
    "\n",
    "\n",
    "# 正解ラベル\n",
    "correct = 10\n",
    "y_train = np_utils.to_categorical(y_train, correct)\n",
    "\n",
    "# テストデータ\n",
    "# 2値化\n",
    "ret, X_test = cv2.threshold(X_test, 127, 255, cv2.THRESH_BINARY)\n",
    "X_test = X_test.reshape(10000, 28, 28, 1)\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "\n",
    "y_test = np_utils.to_categorical(y_test, correct)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.max()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
